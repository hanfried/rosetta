{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training on full dataset with attention model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's a copy+paste version of the original [Attention model with tensorflow](AttentionModelForMachineTranslationWithTensorflow.ipynb) but now with close to the full [European Parliament Proceedings Parallel Corpus 1996-2011](http://statmt.org/europarl/) english-german translations. I only used 95% of the translation corpus as the remaining 5 percent are very long and would increase total training time a lot (I already needed ~40h here for the training).\n",
    "\n",
    "Before the training I also tried to stack multiple layers of RNNs for encoder/decoder. I only got marginal improvements: I could only see a slight decreasement of validation loss, but not really in translation quality. As adding layers increasing training time significant and increases chance of overfitting, I passed to continue this path. Usually, without attention model, additional layers would help, but it seems like [Attention is all you need](https://arxiv.org/abs/1706.03762) is true. The [Google NMT model](https://arxiv.org/pdf/1609.08144.pdf) works with 8 layers on encoder (only first layer bidirectional) and 8 layers on decoders and residual connections. Sounds reasonable but for a side project it's probably too much computational intense (Google itself uses low precision arithmetic and there specialised TPU hardware).\n",
    "\n",
    "Now, I train on sentences with lengths _per sentence_ of up to 400 chars. So _one_ sentence can be up to five usual typewriter lines! It's a parliament corpus and our european representatives (many of them are lawyers) are certainly good in formulating very complicated and hard to understand nested sentence (much longer than this one). So, translation is a really tough task here on high level. Note, for some technical reasons (of the used pretrained bytepairencoding embeddings) I preprocess the input to lowercase and reduce all numbers to 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-23T14:50:03.110063Z",
     "start_time": "2018-06-23T14:50:01.817835Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 10899378753239656055\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 7735830119\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 13522463194795574981\n",
      "physical_device_desc: \"device: 0, name: GeForce GTX 1080, pci bus id: 0000:01:00.0, compute capability: 6.1\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "# Check that there is a GPU\n",
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-23T14:50:03.133883Z",
     "start_time": "2018-06-23T14:50:03.111714Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[22. 28.]\n",
      " [49. 64.]]\n"
     ]
    }
   ],
   "source": [
    "# Check that Cuda/Cudnn/GPU works as intended\n",
    "import tensorflow as tf\n",
    "with tf.device('/gpu:0'):\n",
    "    a = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[2, 3], name='a')\n",
    "    b = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[3, 2], name='b')\n",
    "    c = tf.matmul(a, b)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run(c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-23T14:50:03.844440Z",
     "start_time": "2018-06-23T14:50:03.135700Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fixed random seed to 42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.layers import core as layers_core\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "from utils.download import download_and_extract_resources\n",
    "from utils.linguistic import bleu_scores_europarl, preprocess_input_europarl as preprocess\n",
    "from utils.preparation import Europarl, RANDOM_STATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-23T14:50:03.848109Z",
     "start_time": "2018-06-23T14:50:03.845723Z"
    }
   },
   "outputs": [],
   "source": [
    "MAX_INPUT_LENGTH = 400\n",
    "MAX_TARGET_LENGTH = 450\n",
    "LATENT_DIM =  256  # was 512, but we should be able to use a smaller hidden representation as we are looking back anyway as needed\n",
    "EPOCHS = 20\n",
    "BATCH_SIZE = 128  # was 64, but tensorflow implementation doesn't need so much GPU memory so can increase batch size\n",
    "DROPOUT = 0.25  # Dropout on input and output for the RNN cells, so effective dropout is 0.5, but works slightly better so\n",
    "TEST_SIZE = 2500\n",
    "BEAM_WIDTH = 5\n",
    "EMBEDDING_TRAINABLE = True  # Improves results significant and for at least it's not the most dominant training time factor (that's the output softmax layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-08T13:03:31.674082Z",
     "start_time": "2018-05-08T13:03:31.670919Z"
    }
   },
   "source": [
    "## Download and explore data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-23T14:50:03.855567Z",
     "start_time": "2018-06-23T14:50:03.849878Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "de-en.tgz already downloaded (188.6 MB)\n",
      "en.wiki.bpe.op5000.model already downloaded (0.3 MB)\n",
      "en.wiki.bpe.op5000.d300.w2v.bin.tar.gz already downloaded (6.2 MB)\n",
      "de.wiki.bpe.op5000.model already downloaded (0.3 MB)\n",
      "de.wiki.bpe.op5000.d300.w2v.bin.tar.gz already downloaded (5.7 MB)\n"
     ]
    }
   ],
   "source": [
    "europarl = Europarl()\n",
    "download_and_extract_resources(fnames_and_urls=europarl.external_resources, dest_path=europarl.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-23T14:57:17.615119Z",
     "start_time": "2018-06-23T14:50:03.856751Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of unfiltered translations 1920209\n",
      "Filtered translations with length between (1, input=400/target=450) characters: 1864679\n"
     ]
    }
   ],
   "source": [
    "europarl.load_and_preprocess(max_input_length=MAX_INPUT_LENGTH, max_target_length=MAX_TARGET_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-23T14:57:17.650145Z",
     "start_time": "2018-06-23T14:57:17.617493Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input_texts</th>\n",
       "      <th>target_texts</th>\n",
       "      <th>input_length</th>\n",
       "      <th>target_length</th>\n",
       "      <th>input_sequences</th>\n",
       "      <th>target_sequences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>resumption of the session</td>\n",
       "      <td>wiederaufnahme der sitzungsperiode</td>\n",
       "      <td>25</td>\n",
       "      <td>34</td>\n",
       "      <td>[1, 344, 146, 498, 90, 6, 3, 3235, 90, 2]</td>\n",
       "      <td>[1, 247, 351, 750, 5, 934, 43, 3158, 4762, 2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i declare resumed the session of the european ...</td>\n",
       "      <td>ich erkläre die am freitag, dem 0. dezember un...</td>\n",
       "      <td>203</td>\n",
       "      <td>217</td>\n",
       "      <td>[1, 305, 1712, 480, 344, 3027, 3, 3235, 90, 6,...</td>\n",
       "      <td>[1, 241, 156, 14, 476, 1252, 6, 46, 333, 324, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>although, as you will have seen, the dreaded '...</td>\n",
       "      <td>wie sie feststellen konnten, ist der gefürchte...</td>\n",
       "      <td>191</td>\n",
       "      <td>185</td>\n",
       "      <td>[1, 651, 4, 18, 983, 329, 126, 1479, 4, 3, 55,...</td>\n",
       "      <td>[1, 167, 54, 604, 1191, 1403, 4, 30, 5, 596, 3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>you have requested a debate on this subject in...</td>\n",
       "      <td>im parlament besteht der wunsch nach einer aus...</td>\n",
       "      <td>105</td>\n",
       "      <td>110</td>\n",
       "      <td>[1, 983, 126, 1026, 152, 20, 9, 2033, 118, 19,...</td>\n",
       "      <td>[1, 13, 2269, 974, 5, 111, 203, 82, 40, 95, 34...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>in the meantime, i should like to observe a mi...</td>\n",
       "      <td>heute möchte ich sie bitten - das ist auch der...</td>\n",
       "      <td>232</td>\n",
       "      <td>217</td>\n",
       "      <td>[1, 7, 3, 520, 133, 1258, 4, 305, 1351, 582, 1...</td>\n",
       "      <td>[1, 402, 2187, 2983, 241, 156, 54, 72, 2099, 7...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         input_texts  \\\n",
       "0                          resumption of the session   \n",
       "1  i declare resumed the session of the european ...   \n",
       "2  although, as you will have seen, the dreaded '...   \n",
       "3  you have requested a debate on this subject in...   \n",
       "4  in the meantime, i should like to observe a mi...   \n",
       "\n",
       "                                        target_texts  input_length  \\\n",
       "0                 wiederaufnahme der sitzungsperiode            25   \n",
       "1  ich erkläre die am freitag, dem 0. dezember un...           203   \n",
       "2  wie sie feststellen konnten, ist der gefürchte...           191   \n",
       "3  im parlament besteht der wunsch nach einer aus...           105   \n",
       "4  heute möchte ich sie bitten - das ist auch der...           232   \n",
       "\n",
       "   target_length                                    input_sequences  \\\n",
       "0             34          [1, 344, 146, 498, 90, 6, 3, 3235, 90, 2]   \n",
       "1            217  [1, 305, 1712, 480, 344, 3027, 3, 3235, 90, 6,...   \n",
       "2            185  [1, 651, 4, 18, 983, 329, 126, 1479, 4, 3, 55,...   \n",
       "3            110  [1, 983, 126, 1026, 152, 20, 9, 2033, 118, 19,...   \n",
       "4            217  [1, 7, 3, 520, 133, 1258, 4, 305, 1351, 582, 1...   \n",
       "\n",
       "                                    target_sequences  \n",
       "0      [1, 247, 351, 750, 5, 934, 43, 3158, 4762, 2]  \n",
       "1  [1, 241, 156, 14, 476, 1252, 6, 46, 333, 324, ...  \n",
       "2  [1, 167, 54, 604, 1191, 1403, 4, 30, 5, 596, 3...  \n",
       "3  [1, 13, 2269, 974, 5, 111, 203, 82, 40, 95, 34...  \n",
       "4  [1, 402, 2187, 2983, 241, 156, 54, 72, 2099, 7...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "europarl.df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-23T14:57:17.654869Z",
     "start_time": "2018-06-23T14:57:17.651696Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English subwords ['▁this', '▁is', '▁a', '▁test', '▁for', '▁pre', 'tr', 'ained', '▁by', 'te', 'pa', 'ire', 'm', 'bed', 'd', 'ings']\n",
      "German subwords ['▁das', '▁ist', '▁ein', '▁test', '▁für', '▁v', 'ort', 'rain', 'ierte', '▁zeich', 'eng', 'ruppen']\n"
     ]
    }
   ],
   "source": [
    "print(\"English subwords\", europarl.bpe_input.sentencepiece.EncodeAsPieces(\"this is a test for pretrained bytepairembeddings\"))\n",
    "print(\"German subwords\", europarl.bpe_target.sentencepiece.EncodeAsPieces(\"das ist ein test für vortrainierte zeichengruppen\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-23T14:57:18.458633Z",
     "start_time": "2018-06-23T14:57:17.656341Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(161, 171)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Those will be the inputs for the seq2seq model (that needs to know how long the sequences can get)\n",
    "max_len_input = europarl.df.input_sequences.apply(len).max()\n",
    "max_len_target = europarl.df.target_sequences.apply(len).max()\n",
    "(max_len_input, max_len_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-23T14:57:18.539019Z",
     "start_time": "2018-06-23T14:57:18.460339Z"
    }
   },
   "outputs": [],
   "source": [
    "train_ids, val_ids = train_test_split(np.arange(europarl.df.shape[0]), test_size=0.1, random_state=RANDOM_STATE)  # fixed random_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-23T14:57:25.350606Z",
     "start_time": "2018-06-23T14:57:18.542885Z"
    }
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "with tf.device('/gpu:0'):\n",
    "\n",
    "    encoder_inputs = tf.placeholder(\n",
    "        shape=(None, None),  # batch_size x max_len_input\n",
    "        dtype=tf.int32,\n",
    "        name='encoder_inputs' \n",
    "    )\n",
    "    batch_size = tf.shape(encoder_inputs)[0]\n",
    "    beam_width = tf.placeholder_with_default(1, shape=[])\n",
    "    dropout = tf.placeholder_with_default(tf.cast(0.0, tf.float32), shape=[])\n",
    "    keep_prob = tf.cast(1.0, tf.float32) - dropout\n",
    "\n",
    "    embedding_encoder = tf.get_variable(\n",
    "        \"embedding_encoder\", \n",
    "        initializer=tf.constant(europarl.bpe_input.embedding_matrix),\n",
    "        trainable=EMBEDDING_TRAINABLE,\n",
    "    )\n",
    "    encoder_emb_inp = tf.nn.embedding_lookup(\n",
    "        embedding_encoder,\n",
    "        encoder_inputs,\n",
    "        name=\"encoder_emb_inp\"\n",
    "    )\n",
    "    \n",
    "    input_sequence_length = tf.placeholder(\n",
    "        shape=(None, ),\n",
    "        dtype=tf.int32,\n",
    "        name='input_sequence_length'\n",
    "    )\n",
    "    \n",
    "    rnn_cell_type = tf.nn.rnn_cell.GRUCell\n",
    "    encoder_forward_cell = tf.nn.rnn_cell.DropoutWrapper(\n",
    "        rnn_cell_type(num_units=LATENT_DIM // 2, name='encoder_forward_cell'),\n",
    "        input_keep_prob=keep_prob,\n",
    "        output_keep_prob=keep_prob,  # state_keep_prob not set as it was not helpful here\n",
    "        dtype=tf.float32,\n",
    "    )\n",
    "    encoder_backward_cell = tf.nn.rnn_cell.DropoutWrapper(\n",
    "        rnn_cell_type(num_units=LATENT_DIM // 2, name='encoder_backward_cell'),\n",
    "        input_keep_prob=keep_prob,\n",
    "        output_keep_prob=keep_prob,\n",
    "        dtype=tf.float32,\n",
    "    )\n",
    "    encoder_bi_outputs, encoder_bi_state = tf.nn.bidirectional_dynamic_rnn(\n",
    "        encoder_forward_cell, encoder_backward_cell,\n",
    "        inputs=encoder_emb_inp,\n",
    "        sequence_length=input_sequence_length,\n",
    "        time_major=False,\n",
    "        dtype=tf.float32,\n",
    "    )\n",
    "    encoder_outputs = tf.concat(encoder_bi_outputs, -1)\n",
    "    encoder_state = tf.concat(encoder_bi_state, -1)\n",
    "    \n",
    "    # Regarding time_major:\n",
    "    # If true, these `Tensors` must be shaped `[max_time, batch_size, depth]`.\n",
    "    # If false, these `Tensors` must be shaped `[batch_size, max_time, depth]`.\n",
    "    # Using `time_major = True` is a bit more efficient because it avoids\n",
    "    # transposes at the beginning and end of the RNN calculation.  However,\n",
    "    # most TensorFlow data is batch-major, so by default this function\n",
    "    # accepts input and emits output in batch-major form.\n",
    "    #\n",
    "    # for simplicity I work with batch major here instead of time_major\n",
    "    # so I don't need to transpose inputs and transpose back for attention mechanism\n",
    "    \n",
    "    decoder_inputs = tf.placeholder(\n",
    "        shape=(None, None),  # batch_size x max_len_target\n",
    "        dtype=tf.int32,\n",
    "        name='decoder_inputs' \n",
    "    )\n",
    "    embedding_decoder = tf.get_variable(\n",
    "        \"embedding_decoder\", \n",
    "        initializer=tf.constant(europarl.bpe_target.embedding_matrix),\n",
    "        trainable=EMBEDDING_TRAINABLE,\n",
    "    )\n",
    "    decoder_emb_inp = tf.nn.embedding_lookup(\n",
    "        embedding_decoder,\n",
    "        decoder_inputs,\n",
    "        name=\"decoder_emb_inp\"\n",
    "    )\n",
    "    \n",
    "    target_sequence_length = tf.placeholder(\n",
    "        shape=(None, ),\n",
    "        dtype=tf.int32,\n",
    "        name='target_sequence_length'\n",
    "    )\n",
    "    \n",
    "    # tiling is necessary to work with BeamSearchDecoder\n",
    "    # read carefully the NOTE on constructor in\n",
    "    # https://www.tensorflow.org/api_docs/python/tf/contrib/seq2seq/AttentionWrapper \n",
    "    tiled_encoder_outputs = tf.contrib.seq2seq.tile_batch(encoder_outputs, multiplier=beam_width)\n",
    "    tiled_encoder_state = tf.contrib.seq2seq.tile_batch(encoder_state, multiplier=beam_width)\n",
    "    tiled_sequence_length = tf.contrib.seq2seq.tile_batch(input_sequence_length, multiplier=beam_width)\n",
    "    \n",
    "    attention_mechanism = tf.contrib.seq2seq.LuongAttention(\n",
    "        LATENT_DIM,\n",
    "        memory=tiled_encoder_outputs,\n",
    "        memory_sequence_length=tiled_sequence_length,\n",
    "        dtype=tf.float32,\n",
    "        name='attention_mechanism',\n",
    "    )\n",
    "    decoder_rnn_cell = tf.nn.rnn_cell.DropoutWrapper(\n",
    "        rnn_cell_type(num_units=LATENT_DIM, name='decoder_cell'),\n",
    "        input_keep_prob=keep_prob,\n",
    "        output_keep_prob=keep_prob,\n",
    "        dtype=tf.float32,\n",
    "    )\n",
    "    decoder_cell = tf.contrib.seq2seq.AttentionWrapper(\n",
    "        decoder_rnn_cell,\n",
    "        attention_mechanism,\n",
    "        attention_layer_size=LATENT_DIM, \n",
    "        name='attention_wrapper',\n",
    "    )\n",
    "\n",
    "    training_helper = tf.contrib.seq2seq.TrainingHelper(\n",
    "        inputs=decoder_emb_inp, \n",
    "        sequence_length=target_sequence_length,\n",
    "        time_major=False,\n",
    "        name=\"decoder_training_helper\",\n",
    "    )\n",
    "    \n",
    "    projection_layer = layers_core.Dense(\n",
    "        units=len(europarl.bpe_target.tokens),\n",
    "        use_bias=False,\n",
    "        name='projection_layer',\n",
    "    )\n",
    "    \n",
    "    initial_state=decoder_cell.zero_state(dtype=tf.float32, batch_size=batch_size).clone(\n",
    "        cell_state=encoder_state\n",
    "    )\n",
    "    decoder = tf.contrib.seq2seq.BasicDecoder(\n",
    "        cell=decoder_cell,\n",
    "        helper=training_helper,\n",
    "        initial_state=initial_state,\n",
    "        output_layer=projection_layer,\n",
    "    )\n",
    "    outputs, _final_state, _final_sequence_length = tf.contrib.seq2seq.dynamic_decode(  \n",
    "        decoder,\n",
    "        output_time_major=False,\n",
    "        impute_finished=False,\n",
    "    )\n",
    "    logits = outputs.rnn_output\n",
    "    \n",
    "    decoder_outputs = tf.placeholder(\n",
    "        shape=(None, None),  # batch_size x max_len_target\n",
    "        dtype=tf.int32,\n",
    "        name='decoder_outputs',\n",
    "    )\n",
    "    target_weights = tf.cast(tf.sequence_mask(target_sequence_length), dtype=tf.float32)\n",
    "    train_loss = tf.contrib.seq2seq.sequence_loss(logits, decoder_outputs, target_weights)\n",
    "\n",
    "    params = tf.trainable_variables()\n",
    "    gradients = tf.gradients(train_loss, params)\n",
    "    clipped_gradients, _ = tf.clip_by_global_norm(\n",
    "        t_list=gradients,\n",
    "        clip_norm=1.,\n",
    "    )\n",
    "    \n",
    "    optimizer = tf.train.AdamOptimizer()\n",
    "    update_step = optimizer.apply_gradients(zip(clipped_gradients, params))\n",
    "    \n",
    "    inference_decoder_initial_state = decoder_cell.zero_state(\n",
    "        dtype=tf.float32,\n",
    "        batch_size=batch_size * beam_width  # tricky and somehow unintuitive, but necessary\n",
    "    ).clone(\n",
    "        cell_state=tiled_encoder_state\n",
    "    )\n",
    "    inference_decoder = tf.contrib.seq2seq.BeamSearchDecoder(\n",
    "        cell=decoder_cell,\n",
    "        embedding=embedding_decoder,\n",
    "        start_tokens=tf.fill([batch_size], europarl.bpe_target.start_token_idx),\n",
    "        end_token=europarl.bpe_target.stop_token_idx,\n",
    "        initial_state=inference_decoder_initial_state,\n",
    "        beam_width=BEAM_WIDTH,\n",
    "        output_layer=projection_layer,\n",
    "        length_penalty_weight=1.0,  # https://machinelearningmastery.com/configure-encoder-decoder-model-neural-machine-translation/\n",
    "    )\n",
    "\n",
    "    \n",
    "    inference_outputs, _inference_final_state, _inference_final_sequence_length = tf.contrib.seq2seq.dynamic_decode(\n",
    "        inference_decoder,\n",
    "        maximum_iterations=tf.round(tf.reduce_max(input_sequence_length) * 2),  # a bit more flexible than max_len_target\n",
    "        impute_finished=False,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-23T14:57:25.362158Z",
     "start_time": "2018-06-23T14:57:25.351892Z"
    }
   },
   "outputs": [],
   "source": [
    "def run_train_batch(batch_ids):\n",
    "    batch_input_sequences = europarl.df.input_sequences.iloc[batch_ids]\n",
    "    batch_input_lengths = batch_input_sequences.apply(len)\n",
    "    batch_target_sequences = europarl.df.target_sequences.iloc[batch_ids]\n",
    "    batch_target_lengths = batch_target_sequences.apply(len) - 1\n",
    "\n",
    "    batch_input_padded = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "        batch_input_sequences,\n",
    "        maxlen=max_len_input,\n",
    "        dtype=int,\n",
    "        padding='post'\n",
    "    )\n",
    "    batch_target_padded = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "        batch_target_sequences,\n",
    "        maxlen=max_len_target,\n",
    "        dtype=int,\n",
    "        padding='post'\n",
    "    )\n",
    "    pred, loss, _ = sess.run(\n",
    "        fetches=[\n",
    "            outputs, train_loss, update_step\n",
    "        ],\n",
    "        feed_dict={\n",
    "            encoder_inputs: batch_input_padded,\n",
    "            input_sequence_length: np.array(batch_input_lengths),\n",
    "            decoder_inputs: batch_target_padded[:, :batch_target_lengths.max()],\n",
    "            target_sequence_length: np.array(batch_target_lengths),\n",
    "            decoder_outputs: batch_target_padded[:, 1:batch_target_lengths.max() + 1],\n",
    "            dropout: DROPOUT,\n",
    "        }\n",
    "    )\n",
    "    return loss\n",
    "\n",
    "def run_val_batch(batch_ids):\n",
    "    batch_input_sequences = europarl.df.input_sequences.iloc[batch_ids]\n",
    "    batch_input_lengths = batch_input_sequences.apply(len)\n",
    "    batch_target_sequences = europarl.df.target_sequences.iloc[batch_ids]\n",
    "    batch_target_lengths = batch_target_sequences.apply(len) - 1\n",
    "\n",
    "    batch_input_padded = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "        batch_input_sequences,\n",
    "        maxlen=max_len_input,\n",
    "        dtype=int,\n",
    "        padding='post'\n",
    "    )\n",
    "    batch_target_padded = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "        batch_target_sequences,\n",
    "        maxlen=max_len_target,\n",
    "        dtype=int,\n",
    "        padding='post'\n",
    "    )\n",
    "    loss = sess.run(\n",
    "        fetches=[train_loss],\n",
    "        feed_dict={\n",
    "            encoder_inputs: batch_input_padded,\n",
    "            input_sequence_length: np.array(batch_input_lengths),\n",
    "            decoder_inputs: batch_target_padded[:, :batch_target_lengths.max()],\n",
    "            target_sequence_length: np.array(batch_target_lengths),\n",
    "            decoder_outputs: batch_target_padded[:, 1:batch_target_lengths.max() + 1],\n",
    "        }\n",
    "    )\n",
    "    return loss\n",
    "\n",
    "def run_validation_loss():\n",
    "    return np.mean([\n",
    "        run_val_batch(ids)\n",
    "        for ids \n",
    "        in np.array_split(val_ids, np.ceil(len(val_ids) / BATCH_SIZE))\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-25T10:05:01.757327Z",
     "start_time": "2018-06-23T14:57:25.363470Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed07e78df19d44f8b64a0b572117ec51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 1', max=13112), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "train_loss 2.8138769 val_loss 1.9964966\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbefb42f82b749bdb3d922f2f2cffa03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 2', max=13112), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "train_loss 2.1779718 val_loss 1.8172414\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0568269cff124823958b4cfe598a8fe4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 3', max=13112), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "train_loss 2.068193 val_loss 1.7540516\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae8bd446a0444498abe97657dd75fca7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 4', max=13112), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "train_loss 2.0192885 val_loss 1.7253596\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "220f37c245b54291b0168e9cf4521238",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 5', max=13112), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "train_loss 1.990736 val_loss 1.7020212\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "472211375b5246ada22fcef39b7fde13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 6', max=13112), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "train_loss 1.9711366 val_loss 1.6883754\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd8276180eed4218a17fcc94d0fc4118",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 7', max=13112), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "train_loss 1.9569423 val_loss 1.6794814\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b706526ce8844a69bbb60fe005be9c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 8', max=13112), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "train_loss 1.9460126 val_loss 1.6664897\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "064afbb40d614652803f6ae73ce99892",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 9', max=13112), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "train_loss 1.9372182 val_loss 1.6598784\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d9afb98ca71488f891bff3ffb8bf503",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 10', max=13112), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "train_loss 1.9297335 val_loss 1.6548756\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1946952a548498187046b4ca769bca0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 11', max=13112), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "train_loss 1.9238572 val_loss 1.6510123\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "287a706da16b47969191193f1ac873f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 12', max=13112), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "train_loss 1.9188092 val_loss 1.6469036\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02166eba648f4fe38fec2abfd25fe8d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 13', max=13112), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "train_loss 1.9143066 val_loss 1.641668\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "593db060b42f42d3b7174579fb916f5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 14', max=13112), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "train_loss 1.9104325 val_loss 1.6381077\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df5a61ed99fa4d689ef3e084820c8a24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 15', max=13112), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "train_loss 1.9070565 val_loss 1.6381866\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc64dc7905e84c1bb484c37e0705465d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 16', max=13112), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "train_loss 1.9039155 val_loss 1.6336378\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73586aabf12648c6b36d5db6c8c52a62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 17', max=13112), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "train_loss 1.9007643 val_loss 1.634092\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7362f172d79a4c35833ce76a4c460fd6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 18', max=13112), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "train_loss 1.8982465 val_loss 1.6273415\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eeca957699154af1b28ca1a274e08977",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 19', max=13112), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "train_loss 1.8959094 val_loss 1.6293005\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7516814caab24056b4eb816e885abded",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 20', max=13112), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "train_loss 1.893739 val_loss 1.6259134\n"
     ]
    }
   ],
   "source": [
    "config = tf.ConfigProto(\n",
    "    allow_soft_placement=True,  # needed as recommendation from https://github.com/tensorflow/tensorflow/issues/2292\n",
    "    log_device_placement=True,\n",
    ")\n",
    "sess = tf.Session(config=config)\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "batches_per_epoch = np.ceil(len(train_ids) / BATCH_SIZE)\n",
    "for epoch in range(EPOCHS):\n",
    "    shuffled_ids = np.random.permutation(train_ids)\n",
    "    batch_splits = np.array_split(shuffled_ids, batches_per_epoch)\n",
    "    train_losses = []\n",
    "    N = len(batch_splits)\n",
    "    with tqdm(batch_splits, desc=f\"Epoch {epoch+1}\") as t:\n",
    "        for train_batch_ids in t:\n",
    "            batch_loss = run_train_batch(train_batch_ids)\n",
    "            train_losses.append(batch_loss)\n",
    "            t.set_postfix(train_loss=np.mean(train_losses))\n",
    "        print(\"train_loss\", np.mean(train_losses), \"val_loss\", run_validation_loss())\n",
    "        \n",
    "validation_input_sequences = europarl.df.input_sequences.iloc[val_ids[:BATCH_SIZE]]\n",
    "validation_input_lengths = validation_input_sequences.apply(len)\n",
    "\n",
    "validation_input_padded = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "    validation_input_sequences,\n",
    "    maxlen=max_len_input,\n",
    "    dtype=int,\n",
    "    padding='post'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-25T10:05:01.771667Z",
     "start_time": "2018-06-25T10:05:01.761225Z"
    }
   },
   "outputs": [],
   "source": [
    "def predict(sentence):\n",
    "    sequenced = europarl.bpe_input.subword_indices(preprocess(sentence))\n",
    "    padded = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "        [sequenced],\n",
    "        maxlen=max_len_input,\n",
    "        dtype=int,\n",
    "        padding='post'\n",
    "    )\n",
    "    \n",
    "    beam_search_output = sess.run(\n",
    "        fetches=[inference_outputs],\n",
    "        feed_dict={\n",
    "            encoder_inputs: padded,\n",
    "            input_sequence_length: [len(sequenced)],\n",
    "            beam_width: BEAM_WIDTH,\n",
    "        }\n",
    "    )[0]\n",
    "    \n",
    "    return europarl.bpe_target.sentencepiece.DecodePieces([\n",
    "        europarl.bpe_target.tokens[idx] for idx in beam_search_output.predicted_ids[0, :, 0].tolist()\n",
    "    ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-25T10:05:02.816029Z",
     "start_time": "2018-06-25T10:05:01.775081Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'data/tfattentionmodel.ckpt'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name = 'tfattentionmodel_full'\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "saver.save(sess, f\"data/{name}.ckpt\")\n",
    "# tfattentionmodel_full.ckpt.index https://drive.google.com/open?id=1JzIxjjZqcLIBYBZCal7QnwF6yHemrhv4\n",
    "# tfattentionmodel_full.cpkt.meta https://drive.google.com/open?id=1b5XBioHmCDu_BTgJMl5TiC3vgLGyR_9J\n",
    "# tfattentionmodel_full.cpkt.data-00000-of-00001 https://drive.google.com/open?id=1Fm61A1ghfVysq-BLpoigAOEwsaJ_hzXu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-25T10:05:02.834458Z",
     "start_time": "2018-06-25T10:05:02.817926Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input_texts</th>\n",
       "      <th>target_texts</th>\n",
       "      <th>input_length</th>\n",
       "      <th>target_length</th>\n",
       "      <th>input_sequences</th>\n",
       "      <th>target_sequences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>resumption of the session</td>\n",
       "      <td>wiederaufnahme der sitzungsperiode</td>\n",
       "      <td>25</td>\n",
       "      <td>34</td>\n",
       "      <td>[1, 344, 146, 498, 90, 6, 3, 3235, 90, 2]</td>\n",
       "      <td>[1, 247, 351, 750, 5, 934, 43, 3158, 4762, 2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i declare resumed the session of the european ...</td>\n",
       "      <td>ich erkläre die am freitag, dem 0. dezember un...</td>\n",
       "      <td>203</td>\n",
       "      <td>217</td>\n",
       "      <td>[1, 305, 1712, 480, 344, 3027, 3, 3235, 90, 6,...</td>\n",
       "      <td>[1, 241, 156, 14, 476, 1252, 6, 46, 333, 324, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>although, as you will have seen, the dreaded '...</td>\n",
       "      <td>wie sie feststellen konnten, ist der gefürchte...</td>\n",
       "      <td>191</td>\n",
       "      <td>185</td>\n",
       "      <td>[1, 651, 4, 18, 983, 329, 126, 1479, 4, 3, 55,...</td>\n",
       "      <td>[1, 167, 54, 604, 1191, 1403, 4, 30, 5, 596, 3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>you have requested a debate on this subject in...</td>\n",
       "      <td>im parlament besteht der wunsch nach einer aus...</td>\n",
       "      <td>105</td>\n",
       "      <td>110</td>\n",
       "      <td>[1, 983, 126, 1026, 152, 20, 9, 2033, 118, 19,...</td>\n",
       "      <td>[1, 13, 2269, 974, 5, 111, 203, 82, 40, 95, 34...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>in the meantime, i should like to observe a mi...</td>\n",
       "      <td>heute möchte ich sie bitten - das ist auch der...</td>\n",
       "      <td>232</td>\n",
       "      <td>217</td>\n",
       "      <td>[1, 7, 3, 520, 133, 1258, 4, 305, 1351, 582, 1...</td>\n",
       "      <td>[1, 402, 2187, 2983, 241, 156, 54, 72, 2099, 7...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         input_texts  \\\n",
       "0                          resumption of the session   \n",
       "1  i declare resumed the session of the european ...   \n",
       "2  although, as you will have seen, the dreaded '...   \n",
       "3  you have requested a debate on this subject in...   \n",
       "4  in the meantime, i should like to observe a mi...   \n",
       "\n",
       "                                        target_texts  input_length  \\\n",
       "0                 wiederaufnahme der sitzungsperiode            25   \n",
       "1  ich erkläre die am freitag, dem 0. dezember un...           203   \n",
       "2  wie sie feststellen konnten, ist der gefürchte...           191   \n",
       "3  im parlament besteht der wunsch nach einer aus...           105   \n",
       "4  heute möchte ich sie bitten - das ist auch der...           232   \n",
       "\n",
       "   target_length                                    input_sequences  \\\n",
       "0             34          [1, 344, 146, 498, 90, 6, 3, 3235, 90, 2]   \n",
       "1            217  [1, 305, 1712, 480, 344, 3027, 3, 3235, 90, 6,...   \n",
       "2            185  [1, 651, 4, 18, 983, 329, 126, 1479, 4, 3, 55,...   \n",
       "3            110  [1, 983, 126, 1026, 152, 20, 9, 2033, 118, 19,...   \n",
       "4            217  [1, 7, 3, 520, 133, 1258, 4, 305, 1351, 582, 1...   \n",
       "\n",
       "                                    target_sequences  \n",
       "0      [1, 247, 351, 750, 5, 934, 43, 3158, 4762, 2]  \n",
       "1  [1, 241, 156, 14, 476, 1252, 6, 46, 333, 324, ...  \n",
       "2  [1, 167, 54, 604, 1191, 1403, 4, 30, 5, 596, 3...  \n",
       "3  [1, 13, 2269, 974, 5, 111, 203, 82, 40, 95, 34...  \n",
       "4  [1, 402, 2187, 2983, 241, 156, 54, 72, 2099, 7...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "europarl.df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-25T10:05:03.616496Z",
     "start_time": "2018-06-25T10:05:02.836204Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'hello.' --> 'helfen.'\n",
      "'you are welcome.' --> 'sie begrüßen.'\n",
      "'how do you do?' --> 'wie tun sie?'\n",
      "'i hate mondays.' --> 'ich habe die antwort.'\n",
      "'i am a programmer.' --> 'ich bin ein problem.'\n",
      "'data is the new oil.' --> 'daten ist das neue öl.'\n",
      "'it could be worse.' --> 'es könnte noch schlimmer sein.'\n",
      "'i am on top of it.' --> 'ich bin überhaupt.'\n",
      "'n° uno' --> 'nito-doo'\n",
      "'awesome!' --> 'ein willkommen!'\n",
      "'put your feet up!' --> 'ich habe ihre füße!'\n",
      "'from the start till the end!' --> 'aus dem anfang!'\n",
      "'from dusk till dawn.' --> 'aus duskus tatsächlich geht es darum.'\n"
     ]
    }
   ],
   "source": [
    "# Performance on some examples:\n",
    "EXAMPLES = [\n",
    "    'Hello.',\n",
    "    'You are welcome.',\n",
    "    'How do you do?',\n",
    "    'I hate mondays.',\n",
    "    'I am a programmer.',\n",
    "    'Data is the new oil.',\n",
    "    'It could be worse.',\n",
    "    \"I am on top of it.\",\n",
    "    \"N° Uno\",\n",
    "    \"Awesome!\",\n",
    "    \"Put your feet up!\",\n",
    "    \"From the start till the end!\",\n",
    "    \"From dusk till dawn.\",\n",
    "]\n",
    "for en in [sentence + '\\n' for sentence in EXAMPLES]:\n",
    "    print(f\"{preprocess(en)!r} --> {predict(en)!r}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-25T10:05:05.724671Z",
     "start_time": "2018-06-25T10:05:03.617657Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original 'i declare resumed the session of the european parliament adjourned on friday 0 december 0, and i would like once again to wish you a happy new year in the hope that you enjoyed a pleasant festive period.', got 'ich erkläre die sitzungsperiode des europäischen parlaments am freitag am freitag 0. dezember 0 unterbrochen, und ich möchte noch einmal wünschen, dass sie in der hoffnung, dass sie eine freude festgelegten feiertage haben.', exp: 'ich erkläre die am freitag, dem 0. dezember unterbrochene sitzungsperiode des europäischen parlaments für wiederaufgenommen, wünsche ihnen nochmals alles gute zum jahreswechsel und hoffe, daß sie schöne ferien hatten.'\n",
      "Original \"although, as you will have seen, the dreaded 'millennium bug' failed to materialise, still the people in a number of countries suffered a series of natural disasters that truly were dreadful.\", got 'obwohl sie, wie sie gesehen haben, die schreckliche \"millennium-muggel\" versagt haben, müssen die menschen in einigen ländern eine reihe von naturkatastrophen leiden, die wirklich schrecklich waren.', exp: 'wie sie feststellen konnten, ist der gefürchtete \"millenium-bug \" nicht eingetreten. doch sind bürger einiger unserer mitgliedstaaten opfer von schrecklichen naturkatastrophen geworden.'\n",
      "Original 'you have requested a debate on this subject in the course of the next few days, during this part-session.', got 'sie haben eine debatte über dieses thema in den nächsten tagen in den nächsten tagen beantragt.', exp: 'im parlament besteht der wunsch nach einer aussprache im verlauf dieser sitzungsperiode in den nächsten tagen.'\n",
      "Original \"in the meantime, i should like to observe a minute' s silence, as a number of members have requested, on behalf of all the victims concerned, particularly those of the terrible storms, in the various countries of the european union.\", got 'inzwischen möchte ich eine schweigeminute aufmerksam machen, wie einige abgeordnete im namen aller betroffenen betroffenen betreffenden betroffenen, insbesondere diejenigen, die in den verschiedenen ländern der europäischen union gefordert haben, ein schweigen.', exp: 'heute möchte ich sie bitten - das ist auch der wunsch einiger kolleginnen und kollegen -, allen opfern der stürme, insbesondere in den verschiedenen ländern der europäischen union, in einer schweigeminute zu gedenken.'\n",
      "Original \"please rise, then, for this minute' s silence.\", got 'ich bitte sie bitte, diese minute zu schweigen.', exp: 'ich bitte sie, sich zu einer schweigeminute zu erheben.'\n",
      "Original \"(the house rose and observed a minute' s silence)\", got '(das parlament erhebt sich eine schweigeminute.)', exp: '(das parlament erhebt sich zu einer schweigeminute.)'\n",
      "Original 'madam president, on a point of order.', got 'frau präsidentin!', exp: 'frau präsidentin, zur geschäftsordnung.'\n",
      "Original 'you will be aware from the press and television that there have been a number of bomb explosions and killings in sri lanka.', got 'sie werden vom presse und fernsehen bekannt sein, dass es eine reihe von bombenbooten und töten in sri lanka gab.', exp: 'wie sie sicher aus der presse und dem fernsehen wissen, gab es in sri lanka mehrere bombenexplosionen mit zahlreichen toten.'\n",
      "Original 'one of the people assassinated very recently in sri lanka was mr kumar ponnambalam, who had visited the european parliament just a few months ago.', got 'einer der menschen, die in sri lanka sehr kürzlich in sri lanka eingegangen sind, war herrn kumar ponardamat, der das europäische parlament vor einigen monaten besucht hatte.', exp: 'zu den attentatsopfern, die es in jüngster zeit in sri lanka zu beklagen gab, zählt auch herr kumar ponnambalam, der dem europäischen parlament erst vor wenigen monaten einen besuch abgestattet hatte.'\n",
      "Original \"would it be appropriate for you, madam president, to write a letter to the sri lankan president expressing parliament's regret at his and the other violent deaths in sri lanka and urging her to do everything she possibly can to seek a peaceful reconciliation to a very difficult situation?\", got 'wäre es richtig, dass sie, frau präsidentin, ein schreiben an den sri lankanischen präsident aussprechen, das das parlament zu seinem bedauern und den anderen gewalttaten in sri lanka ausdrückt und sie dringend erfordert, alles, was sie möglicherweise in sri lanka tun kann, zu tun, um eine friedliche versöhnung zu einer sehr schwierigen situation zu suchen?', exp: 'wäre es angemessen, wenn sie, frau präsidentin, der präsidentin von sri lanka in einem schreiben das bedauern des parlaments zum gewaltsamen tod von herrn ponnambalam und anderen bürgern von sri lanka übermitteln und sie auffordern würden, alles in ihrem kräften stehende zu tun, um nach einer friedlichen lösung dieser sehr schwierigen situation zu suchen?'\n",
      "Original 'yes, mr evans, i feel an initiative of the type you have just suggested would be entirely appropriate.', got 'ja, herr evans, ich halte eine initiative der art, die sie gerade vorgeschlagen haben, völlig angemessen.', exp: 'ja, herr evans, ich denke, daß eine derartige initiative durchaus angebracht ist.'\n",
      "Original 'if the house agrees, i shall do as mr evans has suggested.', got 'wenn das plenum abstimmt, werde ich die kolleginnen und kollegen, wie herr evans vorgeschlagen hat, vorgeschlagen.', exp: 'wenn das haus damit einverstanden ist, werde ich dem vorschlag von herrn evans folgen.'\n",
      "Original 'madam president, on a point of order.', got 'frau präsidentin!', exp: 'frau präsidentin, zur geschäftsordnung.'\n",
      "Original 'i would like your advice about rule 0 concerning inadmissibility.', got 'ich möchte ihre empfehlung über artikel 0 über die unverzichtbarkeit von artikel 0 begrüßen.', exp: 'könnten sie mir eine auskunft zu artikel 0 im zusammenhang mit der unzulässigkeit geben?'\n",
      "Original 'my question relates to something that will come up on thursday and which i will then raise again.', got 'meine frage bezieht sich auf etwas, das am donnerstag am donnerstag kommen wird, und ich werde dann wiederholen.', exp: 'meine frage betrifft eine angelegenheit, die am donnerstag zur sprache kommen wird und auf die ich dann erneut verweisen werde.'\n",
      "Original 'the cunha report on multiannual guidance programmes comes before parliament on thursday and contains a proposal in paragraph 0 that a form of quota penalties should be introduced for countries which fail to meet their fleet reduction targets annually.', got 'der bericht cunha über mehrjährige leitlinien im parlament kommt vor dem parlament am donnerstag vor, und enthält einen vorschlag in ziffer 0, daß eine form von quotenstrafen für länder eingeführt werden soll, die ihre flottenkriterien nicht erfüllen.', exp: 'das parlament wird sich am donnerstag mit dem cunha-bericht über mehrjährige ausrichtungsprogramme befassen, der in absatz 0 vorschlägt, daß länder, die ihr soll zur flottenverkleinerung nicht erfüllen, jährlich mit einer art quotenstrafe belegt werden sollen.'\n",
      "Original 'it says that this should be done despite the principle of relative stability.', got 'es sagt, dass dies trotz des grundsatzes der relativen stabilität erfolgen sollte.', exp: 'und zwar sollen derartige strafen trotz des grundsatzes der relativen stabilität verhängt werden.'\n",
      "Original 'i believe that the principle of relative stability is a fundamental legal principle of the common fisheries policy and a proposal to subvert it would be legally inadmissible.', got 'ich glaube, dass das prinzip der relativen stabilität ein grundlegendes rechtsgrundsatz der gemeinsamen fischereipolitik ist und einen vorschlag für die werbung vorlegen würde.', exp: 'ich meine, daß der grundsatz der relativen stabilität einen elementaren rechtsgrundsatz der gemeinsamen fischereipolitik darstellt und ein vorschlag, diesen zu unterlaufen, rechtlich unzulässig wäre.'\n",
      "Original 'i want to know whether one can raise an objection of that kind to what is merely a report, not a legislative proposal, and whether that is something i can competently do on thursday.', got 'ich möchte gerne wissen, ob man ein einspruch auf eine solche art und weise ansprechen kann, was nur ein bericht ist, kein legislativvorschlag, und ob das, was ich am donnerstag tun kann, zustimmen kann.', exp: 'ich möchte wissen, ob es möglich ist, einen einwand gegen ein dokument zu erheben, bei dem es sich lediglich um einen bericht und keinen legislativvorschlag handelt, und ob ich befugt bin, dies am donnerstag zu tun.'\n"
     ]
    }
   ],
   "source": [
    "# Performance on training set:\n",
    "for en, de in europarl.df[['input_texts', 'target_texts']][1:20].values.tolist():\n",
    "    print(f\"Original {en!r}, got {predict(en)!r}, exp: {de!r}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-25T10:05:07.512259Z",
     "start_time": "2018-06-25T10:05:05.725959Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original 'it is important not to underestimate the work involved.', got 'es ist wichtig, die arbeit zu unterschätzen.', exp: 'das sollte man nicht unterschätzen.'\n",
      "Original 'mr vanhanen, you were mr calm, and i think you, mr tuomioja, were mr collected.', got 'herr vanhanen, sie waren kollege kollege, und ich glaube, herr tuioja, herr kommissar.', exp: 'herr vanhanen, sie waren mr. calm, und, ich denke, sie, herr tuomioja, waren mr. collected.'\n",
      "Original \"most members of this parliament are aware of the commission's efforts to make sure that the european support for the palestinian authority is money that is properly spent, well spent and spent in ways that help to promote pluralism, the rule of law and clean government in the palestinian territories.\", got 'die meisten mitglieder dieses parlaments sind sich der bemühungen der kommission bewusst, sicherzustellen, dass die europäische unterstützung für die palästinensische autonomiebehörde gut ausgegeben wird, gut ausgegeben und ausgegeben wird, um die pluralismus, die rechtsstaatlichkeit und die saubere regierung in den palästinensischen gebieten zu fördern.', exp: 'die meisten abgeordneten dieses parlaments wissen um die bemühungen der kommission, dafür zu sorgen, dass die hilfe der eu für die palästinensische autonomiebehörde gut angelegt ist, dass die bereitgestellten mittel für zwecke ausgegeben werden, die der förderung des pluralismus, der rechtsstaatlichkeit und der bekämpfung der korruption in den palästinensischen gebieten dienen.'\n",
      "Original 'i therefore advocate that the eu and russia must step up negotiations on a new partnership and cooperation agreement based on the mutual interdependence of the eu and russia.', got 'ich befürworte daher, dass die eu und russland die verhandlungen über ein neues partnerschafts- und kooperationsabkommen auf der grundlage der gegenseitigen abhängigkeit der eu und russland verfolgen müssen.', exp: 'deswegen befürworte ich, dass die eu und russland ihre verhandlungen über ein neues partnerschafts- und kooperationsabkommen auf der grundlage der gegenseitigen abhängigkeit der eu und russland intensivieren.'\n",
      "Original 'the work to be done on logistics does not involve regulating this rapidly growing sector, but ensuring that it has a sustainable future by allowing it to mobilise the efficiency potential that still exists in the transport business.', got 'die arbeit der logistik ist nicht einbeziehbar, um diesen rapide sektor zu regulieren, sondern sicherzustellen, dass sie eine nachhaltige zukunft hat, um die effizienz potenzial zu mobilisieren, die im verkehrsbereich noch immer vorhanden ist.', exp: 'ziel der anstrengungen auf dem gebiet der logistik ist es nicht, diesen wachstumssektor zu reglementieren, sondern ihm eine nachhaltige zukunft zu sichern, indem er die möglichkeit erhält, das noch im verkehrssektor vorhandene effizienzpotenzial zu mobilisieren.'\n",
      "Original 'nevertheless a comparison of national legislations would be an important factor when we adopt common rules at european level.', got 'dennoch wäre ein vergleich der nationalen rechtsvorschriften ein wichtiger faktor, wenn wir gemeinsame regeln auf europäischer ebene annehmen.', exp: 'trotzdem wäre ein vergleich der nationalen rechtsvorschriften ein wichtiger faktor, wenn auf europäischer ebene gemeinsame regelungen verabschiedet werden.'\n",
      "Original \"from this point of view, we accept the commission proposal in that - and this should be made very clear here - the genuine political debate will come about when we see what the council makes of the commission's preliminary draft budget.\", got 'aus diesem grund akzeptieren wir den vorschlag der kommission, in dem - und dies sollte hier sehr deutlich gemacht werden - die echte politische debatte überlegen wird, wenn wir sehen, was der rat vorentwurf des haushaltsentwurfs der kommission macht.', exp: 'aus dieser sicht heraus machen wir uns den vorschlag der kommission in dem bewußtsein - und das wollen wir hier klarstellen - zu eigen, daß die wirkliche politische debatte erst dann beginnt, wenn feststeht, wie der rat den haushaltsvorentwurf der kommission aufnimmt.'\n",
      "Original 'this is also the main reason why the council took so long to adopt this framework decision.', got 'dies ist auch der hauptgrund, weshalb der rat so lange angenommen hat, um diesen rahmenbeschluss zu verabschieden.', exp: 'das ist auch der hauptgrund dafür, weshalb die annahme des rahmenbeschlusses durch den rat so lange gedauert hat.'\n",
      "Original '(the oral amendment was adopted)', got '(der mündliche änderungsantrag wurde angenommen.)', exp: '(der mündliche änderungsantrag wird angenommen)'\n",
      "Original 'the adoption of this text now enables us to express our initial position.', got 'die annahme dieses textes ist jetzt ermöglicht, unsere ursprüngliche position zu äußern.', exp: 'wenn wir den text jetzt verabschieden, können wir unsere anfängliche haltung zum ausdruck bringen.'\n",
      "Original 'if new priorities are to be added each year, further resources must also be provided.', got 'wenn neue prioritäten hinzugefügt werden, müssen weitere ressourcen vorausgesetzt werden.', exp: 'wenn wir jedes jahr neue prioritäten hinzufügen wollen, müssen wir auch neue ressourcen zur verfügung stellen.'\n",
      "Original 'for the sake of peace and for europe, i very much hope that it can be put into practice and that it will be successful.', got 'für den frieden und für europa, ich hoffe sehr, dass sie in die praxis umgesetzt werden kann und dass sie erfolgreich sein wird.', exp: 'für den frieden und für europa ist es mein dringlicher wunsch, daß dieses beispiel konkrete gestalt annehmen und zu einem erfolg führen möge.'\n",
      "Original 'sixty per cent of them said that they want the uk to renegotiate our relationship with the european union to a simple free trade agreement and no more than that.', got 'sechzig prozent von ihnen haben gesagt, dass sie das vereinigte königreich verhandeln wollen, um unsere beziehungen zur europäischen union zu einem einfachen freihandelsabkommen zu verhandeln und nicht mehr als das zu verhandeln.', exp: 'sechzig prozent der befragten firmen forderten, dass das vereinigte königreich seine beziehungen zur europäischen union dahin gehend ändern soll, dass nur noch ein einfaches freihandelsabkommen mit ihr besteht und nicht mehr.'\n",
      "Original 'over and again, we have said that it needs to be done by relaunching the lisbon strategy, but that strategy will continue to fade away if we do not invest seriously and forcefully in industrial policy.', got 'ich habe noch einmal gesagt, dass es notwendig ist, um die lissabon-strategie zu ergreifen, aber diese strategie wird weiterhin unzureichend sein, wenn wir nicht ernsthaft und in der industriepolitik nicht ernsthafte und gewaltige investitionen investieren.', exp: 'wir haben immer wieder betont, dass das durch eine wiederbelebung der lissabon-strategie geschehen muss, doch diese strategie wird weiter dahinschwinden, wenn wir nicht ernsthaft und energisch in die industriepolitik investieren.'\n",
      "Original 'secondly, we gave this matter very careful consideration at the time we tabled the resolution and we are on no account prepared to withdraw it.', got 'zweitens haben wir diese angelegenheit sehr sorgfältig über die zeit, die wir in der entschließung eingereicht haben, und wir sind nicht bereit, ihn zurückzuziehen.', exp: 'zweitens haben wir den zeitpunkt, zu dem wir diese sache eingebracht haben, sorgfältig erwogen und sind auf keinen fall bereit, die entschließung zurückzuziehen.'\n",
      "Original 'this is a country which has enormous potential - and our readiness to engage with iran constructively has been made over and over.', got 'das ist ein land, das enorme potenzial besitzt - und unsere bereitschaft, mit dem iran konstruktiv zu engagieren.', exp: 'dies ist ein land, welches über ein enormes potenzial verfügt - und unsere bereitschaft, uns konstruktiv auf den iran einzulassen, ist immer wieder gezeigt worden.'\n",
      "Original 'sixthly, the rules which mr solana imposed last year in august without any consultation now fall under this regulation and will also be verified against the same.', got 'sechstens, die vorschriften, die herr solana im vergangenen jahr im august verabschiedet hat, ohne daß jetzt in dieser verordnung eine konsultation unterliegen wird und auch dasselbe gilt.', exp: 'sechstens: die vorschriften, die herr solana im august vergangenen jahres ohne rücksprache durchgesetzt hat, fallen nunmehr unter diese verordnung und werden auch daran geprüft.'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original 'the debate is not therefore whether we are in favour of or opposed to the alternative methods.', got 'die aussprache ist also nicht, ob wir für die alternativen methoden sind oder gegen die alternative methoden sind.', exp: 'es geht also nicht darum, ob wir für oder gegen alternativmethoden sind.'\n",
      "Original 'in conclusion, i would say that only a realistic policy, appropriate to the needs of the population, the environment and an increasingly high-quality market, is capable of achieving the objectives which we think the european union should be aiming at in terms of viticultural policy.', got 'abschließend möchte ich sagen, dass nur eine realistische politik, die für die bedürfnisse der bevölkerung, die umwelt und eine zunehmende qualitativ hochwertige marktwirtschaft angemessen ist, in der lage ist, die ziele zu erreichen, die wir denken, dass die europäische union im hinblick auf die wettbewerbsfähige politik abzielen sollte.', exp: 'abschließend möchte ich feststellen, daß nur eine realistische, auf die bedürfnisse der menschen, der umwelt und den zunehmend qualitätsbetonten markt abgestimmte politik geeignet ist, die ziele, die wir im bereich des weinbaus in der europäischen union politisch verankern wollen, zu verwirklichen.'\n"
     ]
    }
   ],
   "source": [
    "# Performance on validation set\n",
    "val_df = europarl.df.iloc[val_ids]\n",
    "for en, de in val_df[['input_texts', 'target_texts']][1:20].values.tolist():\n",
    "    print(f\"Original {en!r}, got {predict(en)!r}, exp: {de!r}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-25T10:09:08.668361Z",
     "start_time": "2018-06-25T10:05:07.513449Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0bc1e3f4f3a34c3ca7b2fe10555f3da6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=2500), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "average BLEU on test set = 0.19960701983863563\n"
     ]
    }
   ],
   "source": [
    "bleu = bleu_scores_europarl(\n",
    "    input_texts=europarl.df.input_texts.iloc[val_ids[:TEST_SIZE]],\n",
    "    target_texts=europarl.df.target_texts.iloc[val_ids[:TEST_SIZE]],\n",
    "    predict=lambda text: predict(text)\n",
    ")\n",
    "print(f'average BLEU on test set = {bleu.mean()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-13T18:17:20.995932Z",
     "start_time": "2018-05-13T18:17:20.994111Z"
    }
   },
   "source": [
    "# Conclusion\n",
    "\n",
    "Most sentences are astonishing well translated in my opinion. In the real long, convoluted sentences, you can see that the encoder/decoder model really does not have an understanding of grammar (neither in input nor in target language) and makes mistakes. Sometimes the translation is grammatical wrong and so hard to understand. More problematic is, that even sometimes a translation is readable, but just wrong (e.g. when a negation gets lost, like in \"it is important not to underestimate the work involved.' -> 'es ist wichtig, die arbeit zu unterschätzen.'). The translating/transliteration of unknown words (or known words at wrong places \"Mr. Miller\" -> \"Herr Müller\") are problematic. It would be better to learn how to look up/copy them. The repetitions are back, allthough more subtle now.\n",
    "\n",
    "Anyway, at least for me, I'm fascinated as this model really does not know anything of language, nor even the concept of words and works really already well on really complicated sentences. Even most humans will need several years to be better.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-25T14:18:18.778649Z",
     "start_time": "2018-06-25T14:18:18.768897Z"
    }
   },
   "source": [
    "## Further ways to improve\n",
    "\n",
    "### Hyperparameters\n",
    "\n",
    "- *learning rate*: The training jumps around at the last epochs here. This would be good spot to decrease the learning rate either manually or with an automatic decay and train it longer from there.\n",
    "- *latent\\_dim*: For shorter sentences, there were only marginal improvements when using a higher latent embedding size than used here. It would be worth to check whether it might help here, but it would also multiple the training time.\n",
    "- *LSTMS vs GRUs or stacking layers*: Here the bytepair sequences of up to 170 is much longer than what LSTMs/GRUs can remember (something around 60-100 of a sequence length). Again it would be worth to check whether LSTMS instead of GRUs help here (for the sake of doubling parameters) or even add another layer working on a coarse level (like words).\n",
    "\n",
    "For anything intended to use in practice, here we should play around with hyperparams as it does not need engineering power, only (cloud) GPU resources and some time. For me, there's not much to learn, but I don't want to spend much money, so I won't do anything of it.\n",
    "\n",
    "### More data\n",
    "\n",
    "Getting more data for translations should be relatively cheap and it definitly would help the translations. Especially my short self created examples (with words and sentences very different to the corpus) where this model performs terrible could be easily changed with just adding a training on a more simpler training set (like movie sub titles or what ever). Again, there's not much to learn from it for me. So, allthough it would improve the translation quality a lot in practice, I won't put energy in more data.\n",
    "\n",
    "\n",
    "### Convolutional Architecture\n",
    "\n",
    "CNNs can be used also for neural machine translations. Beside that they should be better trainable with a GPU, they also promise to better track grammar structures (with more position-robustness in the sentences) and a global view (in long, convoluted sentences both get lost). They would also be interesting for me to do as I rarely worked with computer vision models, so working with CNNs would be interesting for me, too, and they require a different fine tuning to work with (working with residuals, normalizations, ...). Allthough that's very interesting, I think, I'll postpone this approach till I studied and programmed several CNNs for CV before. \n",
    "\n",
    "### Copy-mechanism\n",
    "\n",
    "It's possible to train a world alignment model (somehow similiar to the attention model) that predicts the relative positions for unknown words. Given such a UNK-alignment model, we can look up unknown words and either translate them with a dictionary or just copy them. That would be very helpful for the many names and entities in this dataset and also for the many numbers (so they don't need to be preprocessed here all to 0). It would also avoid doubled confusion for unknown words, probably more than the translating/transliteration (e.g. \"mr tuomioja\" becomes \"herr tuioja\") that happens now. I'm not sure how difficult it is to implement the copy-mechanism here (especially as the model does not work on word level, but a copy-mechanism would have), but I had this approach in mind from the beginning, so I plan to implement it.\n",
    "\n",
    "### Pointer-Generator Networks\n",
    "\n",
    "It's a technique from summarizing texts that looks also worth to consider for this translation corpus given the long, convoluted sentences. It's described e.g. in [Get To The Point: Summarization with Pointer-Generator Networks](https://arxiv.org/abs/1704.04368), I'll quote the abstract here:\n",
    "\n",
    "> Neural sequence-to-sequence models have provided a viable new approach for abstractive text summarization (meaning they are not restricted to simply selecting and rearranging passages from the original text). However, these models have two shortcomings: they are liable to reproduce factual details inaccurately, and they tend to repeat themselves. In this work we propose a novel architecture that augments the standard sequence-to-sequence attentional model in two orthogonal ways. First, we use a hybrid pointer-generator network that can copy words from the source text via pointing, which aids accurate reproduction of information, while retaining the ability to produce novel words through the generator. Second, we use coverage to keep track of what has been summarized, which discourages repetition. We apply our model to the CNN / Daily Mail summarization task, outperforming the current abstractive state-of-the-art by at least 2 ROUGE points. \n",
    "\n",
    "We can see the mentioned repeatings in the translation model here, too.\n",
    "It might be better to first get a feeling for pointer generator networks on a summerization corpus, first, but I would want to implement the technique also.\n",
    "\n",
    "### Coverage mechanism\n",
    "\n",
    "To avoid repetitions, we can also calculate a coverage vector, then calculate modified attentions respecting the coverage vector. It's probably not so difficult and also something I'd like to try out. \n",
    "\n",
    "### NLU / dynamical neural network memory\n",
    "\n",
    "It is something I had in mind also before hand. They are more important for dialogue managers, but probably the hottest, most magic state-of-the-art technique. Maybe I switch to a dialogue corpus or some toy problem with a lot of remembering first. Here it would anyway help, too, but as errors are more subtle here, it's more difficult to make a start.\n",
    "\n",
    "### Multi learning\n",
    "\n",
    "The dataset is really well suited to learn translations in many different language pairs at once. On a simple Encoder-into-one-big-state-that-is-more-or-less-language-independent/Decode-from-that model, it would be trivial to implement (but then we'd have all the problems back from [a simple model](SimpleModelForMachineTranslation.ipynb)). Attention modelling is not language indepedent, so it might be necessary to translate into a language independent code first and from this intermediate language to the target language. Maybe those dynamic neural network memories are needed, maybe not. I need to check research papers first.\n",
    "\n",
    "Beside the big multi language learning, learning anything else in addition would also help. If the model learns to do entitiy-recognition or part-of-speech, translations would get better, too. Of course, the hard part is to get some annotated data similiar without to cheat (using Google NLP API or so). Not sure, whether NLTK can parse these complicated sentences correctly?! A way to multi-learn words to be marked for copy might be to compare multiple translations for words that are copy+pasted in all translations.\n",
    "\n",
    "### Deploy\n",
    "\n",
    "It would be fun to have the translation model be deployed on a website or as translation bot somewhere.\n",
    "\n",
    "## tl;dr\n",
    "\n",
    "I guess, I'll start implementing copy-mechanism next (and/or deploy it somewhere).\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 294,
   "position": {
    "height": "40px",
    "left": "553px",
    "right": "192px",
    "top": "132px",
    "width": "615px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "none",
   "window_display": true
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
